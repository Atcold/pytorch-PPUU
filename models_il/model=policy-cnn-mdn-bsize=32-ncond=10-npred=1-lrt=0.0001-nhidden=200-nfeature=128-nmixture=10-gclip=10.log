2018-04-26 21:18:47.256734: iter 0 | train loss: 0.90336, valid: 0.41647, best valid loss: 0.41647
2018-04-26 21:19:21.211390: iter 1000 | train loss: -0.34004, valid: -0.76921, best valid loss: -0.76921
2018-04-26 21:19:55.279213: iter 2000 | train loss: -0.94084, valid: -1.51545, best valid loss: -1.51545
2018-04-26 21:20:29.303025: iter 3000 | train loss: -1.41879, valid: -1.81660, best valid loss: -1.81660
2018-04-26 21:21:03.396706: iter 4000 | train loss: -1.40601, valid: -1.88472, best valid loss: -1.88472
2018-04-26 21:21:37.266660: iter 5000 | train loss: -1.84209, valid: -1.83984, best valid loss: -1.88472
2018-04-26 21:22:11.364640: iter 6000 | train loss: -2.01903, valid: -2.11878, best valid loss: -2.11878
2018-04-26 21:22:45.161775: iter 7000 | train loss: -1.78878, valid: -2.11430, best valid loss: -2.11878
2018-04-26 21:23:19.125354: iter 8000 | train loss: -2.14735, valid: -2.45232, best valid loss: -2.45232
2018-04-26 21:23:52.940196: iter 9000 | train loss: -2.26923, valid: -2.20856, best valid loss: -2.45232
2018-04-26 21:24:26.774816: iter 10000 | train loss: -2.33417, valid: -2.43653, best valid loss: -2.45232
2018-04-26 21:25:00.717802: iter 11000 | train loss: -2.41580, valid: -2.56435, best valid loss: -2.56435
2018-04-26 21:25:34.580324: iter 12000 | train loss: -2.47016, valid: -2.48191, best valid loss: -2.56435
2018-04-26 21:26:08.538311: iter 13000 | train loss: -2.67713, valid: -2.76707, best valid loss: -2.76707
2018-04-26 21:26:42.582788: iter 14000 | train loss: -2.88741, valid: -3.03306, best valid loss: -3.03306
2018-04-26 21:27:16.661199: iter 15000 | train loss: -3.11018, valid: -3.14660, best valid loss: -3.14660
2018-04-26 21:27:50.714106: iter 16000 | train loss: -3.18180, valid: -3.30628, best valid loss: -3.30628
2018-04-26 21:28:24.779678: iter 17000 | train loss: -3.31307, valid: -3.41804, best valid loss: -3.41804
2018-04-26 21:28:58.836463: iter 18000 | train loss: -3.37166, valid: -3.53209, best valid loss: -3.53209
2018-04-26 21:29:32.792375: iter 19000 | train loss: -3.43517, valid: -3.54217, best valid loss: -3.54217
2018-04-26 21:30:06.825101: iter 20000 | train loss: -3.57423, valid: -3.76273, best valid loss: -3.76273
2018-04-26 21:30:40.632498: iter 21000 | train loss: -3.62287, valid: -3.52799, best valid loss: -3.76273
2018-04-26 21:31:14.495500: iter 22000 | train loss: -3.68636, valid: -3.63715, best valid loss: -3.76273
2018-04-26 21:31:48.518965: iter 23000 | train loss: -3.70353, valid: -4.02773, best valid loss: -4.02773
2018-04-26 21:32:22.370264: iter 24000 | train loss: -3.76473, valid: -3.63205, best valid loss: -4.02773
2018-04-26 21:32:56.249086: iter 25000 | train loss: -3.91572, valid: -4.01472, best valid loss: -4.02773
2018-04-26 21:33:30.160043: iter 26000 | train loss: -3.92399, valid: -3.95302, best valid loss: -4.02773
2018-04-26 21:34:04.088892: iter 27000 | train loss: -3.94434, valid: -3.86459, best valid loss: -4.02773
2018-04-26 21:34:38.201240: iter 28000 | train loss: -4.00867, valid: -4.23604, best valid loss: -4.23604
2018-04-26 21:35:12.207513: iter 29000 | train loss: -4.06855, valid: -4.30921, best valid loss: -4.30921
2018-04-26 21:35:46.188459: iter 30000 | train loss: -4.03622, valid: -4.36410, best valid loss: -4.36410
2018-04-26 21:36:20.014713: iter 31000 | train loss: -4.09216, valid: -4.32191, best valid loss: -4.36410
2018-04-26 21:36:53.773826: iter 32000 | train loss: -4.16500, valid: -4.12859, best valid loss: -4.36410
2018-04-26 21:37:27.624410: iter 33000 | train loss: -4.15199, valid: -3.79922, best valid loss: -4.36410
2018-04-26 21:38:01.382315: iter 34000 | train loss: -4.25314, valid: -4.16723, best valid loss: -4.36410
2018-04-26 21:38:35.416243: iter 35000 | train loss: -4.28260, valid: -4.55666, best valid loss: -4.55666
2018-04-26 21:39:09.232787: iter 36000 | train loss: -4.32307, valid: -4.53613, best valid loss: -4.55666
2018-04-26 21:39:43.130747: iter 37000 | train loss: -4.35288, valid: -4.47273, best valid loss: -4.55666
2018-04-26 21:40:17.128949: iter 38000 | train loss: -4.37560, valid: -4.65229, best valid loss: -4.65229
2018-04-26 21:40:51.058916: iter 39000 | train loss: -4.42344, valid: -4.61199, best valid loss: -4.65229
2018-04-26 21:41:25.538927: iter 40000 | train loss: -4.43285, valid: -4.75864, best valid loss: -4.75864
2018-04-26 21:41:59.450474: iter 41000 | train loss: -4.50364, valid: -4.34931, best valid loss: -4.75864
2018-04-26 21:42:33.315323: iter 42000 | train loss: -4.45969, valid: -4.60787, best valid loss: -4.75864
2018-04-26 21:43:07.216268: iter 43000 | train loss: -4.47742, valid: -4.47059, best valid loss: -4.75864
2018-04-26 21:43:41.160802: iter 44000 | train loss: -4.57822, valid: -4.71284, best valid loss: -4.75864
2018-04-26 21:44:14.998550: iter 45000 | train loss: -4.58372, valid: -4.49597, best valid loss: -4.75864
2018-04-26 21:44:48.888895: iter 46000 | train loss: -4.58659, valid: -4.52129, best valid loss: -4.75864
2018-04-26 21:45:22.731590: iter 47000 | train loss: -4.63525, valid: -4.72819, best valid loss: -4.75864
2018-04-26 21:45:56.780949: iter 48000 | train loss: -4.63514, valid: -4.76406, best valid loss: -4.76406
2018-04-26 21:46:30.773280: iter 49000 | train loss: -4.64270, valid: -4.91206, best valid loss: -4.91206
2018-04-26 21:47:04.550495: iter 50000 | train loss: nan, valid: nan, best valid loss: -4.91206
2018-04-26 21:47:38.274356: iter 51000 | train loss: nan, valid: nan, best valid loss: -4.91206
2018-04-26 21:48:12.087410: iter 52000 | train loss: nan, valid: nan, best valid loss: -4.91206
2018-04-26 21:48:45.785589: iter 53000 | train loss: nan, valid: nan, best valid loss: -4.91206
2018-04-26 21:49:19.599404: iter 54000 | train loss: nan, valid: nan, best valid loss: -4.91206
2018-04-26 21:49:53.305281: iter 55000 | train loss: nan, valid: nan, best valid loss: -4.91206
2018-04-26 21:50:27.106302: iter 56000 | train loss: nan, valid: nan, best valid loss: -4.91206
2018-04-26 21:51:00.872561: iter 57000 | train loss: nan, valid: nan, best valid loss: -4.91206
2018-04-26 21:51:34.692816: iter 58000 | train loss: nan, valid: nan, best valid loss: -4.91206
2018-04-26 21:52:08.411608: iter 59000 | train loss: nan, valid: nan, best valid loss: -4.91206
2018-04-26 21:52:42.237030: iter 60000 | train loss: nan, valid: nan, best valid loss: -4.91206
2018-04-26 21:53:15.960324: iter 61000 | train loss: nan, valid: nan, best valid loss: -4.91206
2018-04-26 21:53:49.725435: iter 62000 | train loss: nan, valid: nan, best valid loss: -4.91206
2018-04-26 21:54:23.483530: iter 63000 | train loss: nan, valid: nan, best valid loss: -4.91206
2018-04-26 21:54:57.254987: iter 64000 | train loss: nan, valid: nan, best valid loss: -4.91206
2018-04-26 21:55:31.044204: iter 65000 | train loss: nan, valid: nan, best valid loss: -4.91206
2018-04-26 21:56:04.826032: iter 66000 | train loss: nan, valid: nan, best valid loss: -4.91206
2018-04-26 21:56:38.608497: iter 67000 | train loss: nan, valid: nan, best valid loss: -4.91206
2018-04-26 21:57:12.396950: iter 68000 | train loss: nan, valid: nan, best valid loss: -4.91206
2018-04-26 21:57:46.177357: iter 69000 | train loss: nan, valid: nan, best valid loss: -4.91206
2018-04-26 21:58:19.936535: iter 70000 | train loss: nan, valid: nan, best valid loss: -4.91206
2018-04-26 21:58:53.738450: iter 71000 | train loss: nan, valid: nan, best valid loss: -4.91206
2018-04-26 21:59:27.463102: iter 72000 | train loss: nan, valid: nan, best valid loss: -4.91206
2018-04-26 22:00:01.275332: iter 73000 | train loss: nan, valid: nan, best valid loss: -4.91206
2018-04-26 22:00:35.016139: iter 74000 | train loss: nan, valid: nan, best valid loss: -4.91206
2018-04-26 22:01:08.811742: iter 75000 | train loss: nan, valid: nan, best valid loss: -4.91206
2018-04-26 22:01:42.567061: iter 76000 | train loss: nan, valid: nan, best valid loss: -4.91206
2018-04-26 22:02:16.370633: iter 77000 | train loss: nan, valid: nan, best valid loss: -4.91206
2018-04-26 22:02:50.110037: iter 78000 | train loss: nan, valid: nan, best valid loss: -4.91206
2018-04-26 22:03:23.921582: iter 79000 | train loss: nan, valid: nan, best valid loss: -4.91206
2018-04-26 22:03:57.650423: iter 80000 | train loss: nan, valid: nan, best valid loss: -4.91206
2018-04-26 22:04:31.415528: iter 81000 | train loss: nan, valid: nan, best valid loss: -4.91206
2018-04-26 22:05:05.189540: iter 82000 | train loss: nan, valid: nan, best valid loss: -4.91206
2018-04-26 22:05:38.965195: iter 83000 | train loss: nan, valid: nan, best valid loss: -4.91206
2018-04-26 22:06:12.839007: iter 84000 | train loss: nan, valid: nan, best valid loss: -4.91206
2018-04-26 22:06:46.620159: iter 85000 | train loss: nan, valid: nan, best valid loss: -4.91206
2018-04-26 22:07:20.422745: iter 86000 | train loss: nan, valid: nan, best valid loss: -4.91206
2018-04-26 22:07:54.218929: iter 87000 | train loss: nan, valid: nan, best valid loss: -4.91206
2018-04-26 22:08:28.086822: iter 88000 | train loss: nan, valid: nan, best valid loss: -4.91206
2018-04-26 22:09:01.889008: iter 89000 | train loss: nan, valid: nan, best valid loss: -4.91206
2018-04-26 22:09:35.691536: iter 90000 | train loss: nan, valid: nan, best valid loss: -4.91206
2018-04-26 22:10:09.495697: iter 91000 | train loss: nan, valid: nan, best valid loss: -4.91206
2018-04-26 22:10:43.399198: iter 92000 | train loss: nan, valid: nan, best valid loss: -4.91206
2018-04-26 22:11:17.156305: iter 93000 | train loss: nan, valid: nan, best valid loss: -4.91206
2018-04-26 22:11:50.993093: iter 94000 | train loss: nan, valid: nan, best valid loss: -4.91206
2018-04-26 22:12:24.832867: iter 95000 | train loss: nan, valid: nan, best valid loss: -4.91206
2018-04-26 22:12:58.673746: iter 96000 | train loss: nan, valid: nan, best valid loss: -4.91206
2018-04-26 22:13:32.452203: iter 97000 | train loss: nan, valid: nan, best valid loss: -4.91206
2018-04-26 22:14:06.313392: iter 98000 | train loss: nan, valid: nan, best valid loss: -4.91206
2018-04-26 22:14:40.095113: iter 99000 | train loss: nan, valid: nan, best valid loss: -4.91206
