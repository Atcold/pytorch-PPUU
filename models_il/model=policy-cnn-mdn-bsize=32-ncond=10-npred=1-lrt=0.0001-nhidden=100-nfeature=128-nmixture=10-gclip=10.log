2018-04-26 21:18:42.012117: iter 0 | train loss: 0.82992, valid: -0.11574, best valid loss: -0.11574
2018-04-26 21:19:15.533027: iter 1000 | train loss: -0.17889, valid: -0.83320, best valid loss: -0.83320
2018-04-26 21:19:49.205391: iter 2000 | train loss: -0.77506, valid: -1.06346, best valid loss: -1.06346
2018-04-26 21:20:22.869618: iter 3000 | train loss: -0.76757, valid: -1.32257, best valid loss: -1.32257
2018-04-26 21:20:56.501824: iter 4000 | train loss: -1.24429, valid: -1.64357, best valid loss: -1.64357
2018-04-26 21:21:30.117170: iter 5000 | train loss: -1.58200, valid: -1.60524, best valid loss: -1.64357
2018-04-26 21:22:03.774484: iter 6000 | train loss: -1.78765, valid: -1.83165, best valid loss: -1.83165
2018-04-26 21:22:37.521259: iter 7000 | train loss: -1.91497, valid: -2.18201, best valid loss: -2.18201
2018-04-26 21:23:11.176743: iter 8000 | train loss: -2.05966, valid: -2.23395, best valid loss: -2.23395
2018-04-26 21:23:44.870918: iter 9000 | train loss: -2.16690, valid: -2.28873, best valid loss: -2.28873
2018-04-26 21:24:18.338150: iter 10000 | train loss: -2.26590, valid: -2.11866, best valid loss: -2.28873
2018-04-26 21:24:52.066040: iter 11000 | train loss: -2.36666, valid: -2.61127, best valid loss: -2.61127
2018-04-26 21:25:25.542896: iter 12000 | train loss: -2.36478, valid: -2.48075, best valid loss: -2.61127
2018-04-26 21:25:59.088830: iter 13000 | train loss: -2.44295, valid: -2.08344, best valid loss: -2.61127
2018-04-26 21:26:32.586231: iter 14000 | train loss: -2.51943, valid: -2.44324, best valid loss: -2.61127
2018-04-26 21:27:06.260226: iter 15000 | train loss: -2.61040, valid: -2.70958, best valid loss: -2.70958
2018-04-26 21:27:39.932425: iter 16000 | train loss: -2.62756, valid: -2.75104, best valid loss: -2.75104
2018-04-26 21:28:13.576711: iter 17000 | train loss: -2.69449, valid: -2.87606, best valid loss: -2.87606
2018-04-26 21:28:47.251307: iter 18000 | train loss: -2.75425, valid: -3.02989, best valid loss: -3.02989
2018-04-26 21:29:20.806243: iter 19000 | train loss: -2.79349, valid: -2.88486, best valid loss: -3.02989
2018-04-26 21:29:54.380937: iter 20000 | train loss: -2.87501, valid: -2.80669, best valid loss: -3.02989
2018-04-26 21:30:27.900995: iter 21000 | train loss: -2.84802, valid: -2.87614, best valid loss: -3.02989
2018-04-26 21:31:01.594027: iter 22000 | train loss: -2.92669, valid: -3.08606, best valid loss: -3.08606
2018-04-26 21:31:35.069960: iter 23000 | train loss: -2.97447, valid: -3.07803, best valid loss: -3.08606
2018-04-26 21:32:08.783414: iter 24000 | train loss: -3.04018, valid: -3.15349, best valid loss: -3.15349
2018-04-26 21:32:42.289483: iter 25000 | train loss: -3.06570, valid: -2.98298, best valid loss: -3.15349
2018-04-26 21:33:15.858661: iter 26000 | train loss: -3.09635, valid: -2.99640, best valid loss: -3.15349
2018-04-26 21:33:49.367423: iter 27000 | train loss: -3.14268, valid: -3.09780, best valid loss: -3.15349
2018-04-26 21:34:23.068727: iter 28000 | train loss: -3.18501, valid: -3.35167, best valid loss: -3.35167
2018-04-26 21:34:56.731651: iter 29000 | train loss: -3.24611, valid: -3.40356, best valid loss: -3.40356
2018-04-26 21:35:30.331059: iter 30000 | train loss: -3.29719, valid: -3.13846, best valid loss: -3.40356
2018-04-26 21:36:04.140059: iter 31000 | train loss: -3.42575, valid: -3.43641, best valid loss: -3.43641
2018-04-26 21:36:37.751484: iter 32000 | train loss: -3.56433, valid: -3.50044, best valid loss: -3.50044
2018-04-26 21:37:11.464442: iter 33000 | train loss: -3.65252, valid: -3.75715, best valid loss: -3.75715
2018-04-26 21:37:45.122113: iter 34000 | train loss: -3.69732, valid: -3.97509, best valid loss: -3.97509
2018-04-26 21:38:18.832165: iter 35000 | train loss: -3.78817, valid: -4.00738, best valid loss: -4.00738
2018-04-26 21:38:52.328482: iter 36000 | train loss: -3.84809, valid: -3.82447, best valid loss: -4.00738
2018-04-26 21:39:25.877112: iter 37000 | train loss: -3.94057, valid: -3.93925, best valid loss: -4.00738
2018-04-26 21:39:59.343976: iter 38000 | train loss: -4.00144, valid: -3.81998, best valid loss: -4.00738
2018-04-26 21:40:33.065486: iter 39000 | train loss: -4.08447, valid: -4.15745, best valid loss: -4.15745
2018-04-26 21:41:06.596254: iter 40000 | train loss: -4.16181, valid: -4.15278, best valid loss: -4.15745
2018-04-26 21:41:40.393606: iter 41000 | train loss: -4.21192, valid: -4.46264, best valid loss: -4.46264
2018-04-26 21:42:13.926567: iter 42000 | train loss: -4.18385, valid: -4.32184, best valid loss: -4.46264
2018-04-26 21:42:47.481839: iter 43000 | train loss: -4.23380, valid: -4.43988, best valid loss: -4.46264
2018-04-26 21:43:21.026592: iter 44000 | train loss: -4.29176, valid: -4.41307, best valid loss: -4.46264
2018-04-26 21:43:54.522035: iter 45000 | train loss: -4.32055, valid: -4.02872, best valid loss: -4.46264
2018-04-26 21:44:28.250475: iter 46000 | train loss: -4.33692, valid: -4.48707, best valid loss: -4.48707
2018-04-26 21:45:01.966216: iter 47000 | train loss: -4.41215, valid: -4.50480, best valid loss: -4.50480
2018-04-26 21:45:35.543046: iter 48000 | train loss: -4.40825, valid: -4.15202, best valid loss: -4.50480
2018-04-26 21:46:09.033194: iter 49000 | train loss: -4.50465, valid: -4.35058, best valid loss: -4.50480
2018-04-26 21:46:42.579168: iter 50000 | train loss: -4.46214, valid: -4.45033, best valid loss: -4.50480
2018-04-26 21:47:16.190481: iter 51000 | train loss: -4.57657, valid: -4.80970, best valid loss: -4.80970
2018-04-26 21:47:49.775988: iter 52000 | train loss: -4.56082, valid: -4.58608, best valid loss: -4.80970
2018-04-26 21:48:23.389516: iter 53000 | train loss: -4.55509, valid: -4.86592, best valid loss: -4.86592
2018-04-26 21:48:56.925192: iter 54000 | train loss: -4.61028, valid: -4.80160, best valid loss: -4.86592
2018-04-26 21:49:30.415779: iter 55000 | train loss: -4.60366, valid: -4.65117, best valid loss: -4.86592
2018-04-26 21:50:03.946962: iter 56000 | train loss: -4.65771, valid: -4.70374, best valid loss: -4.86592
2018-04-26 21:50:37.439972: iter 57000 | train loss: -4.69705, valid: -4.61426, best valid loss: -4.86592
2018-04-26 21:51:11.067894: iter 58000 | train loss: -4.74231, valid: -4.96338, best valid loss: -4.96338
2018-04-26 21:51:44.658314: iter 59000 | train loss: -4.77360, valid: -4.75346, best valid loss: -4.96338
2018-04-26 21:52:18.296262: iter 60000 | train loss: -4.82406, valid: -5.07625, best valid loss: -5.07625
2018-04-26 21:52:51.875868: iter 61000 | train loss: -4.85862, valid: -4.94338, best valid loss: -5.07625
2018-04-26 21:53:25.380154: iter 62000 | train loss: -4.87137, valid: -4.98912, best valid loss: -5.07625
2018-04-26 21:53:59.117859: iter 63000 | train loss: -4.89774, valid: -5.20892, best valid loss: -5.20892
2018-04-26 21:54:32.655009: iter 64000 | train loss: -4.87556, valid: -5.01216, best valid loss: -5.20892
2018-04-26 21:55:06.302452: iter 65000 | train loss: -4.91522, valid: -4.98910, best valid loss: -5.20892
2018-04-26 21:55:39.831614: iter 66000 | train loss: -4.94073, valid: -4.35505, best valid loss: -5.20892
2018-04-26 21:56:13.449955: iter 67000 | train loss: -4.95759, valid: -4.99553, best valid loss: -5.20892
2018-04-26 21:56:47.151481: iter 68000 | train loss: -4.96493, valid: -5.21807, best valid loss: -5.21807
2018-04-26 21:57:20.682475: iter 69000 | train loss: -4.98966, valid: -5.18050, best valid loss: -5.21807
2018-04-26 21:57:54.177788: iter 70000 | train loss: -5.03011, valid: -5.04787, best valid loss: -5.21807
2018-04-26 21:58:27.699100: iter 71000 | train loss: -5.04516, valid: -4.55180, best valid loss: -5.21807
2018-04-26 21:59:01.239174: iter 72000 | train loss: nan, valid: nan, best valid loss: -5.21807
2018-04-26 21:59:34.725891: iter 73000 | train loss: nan, valid: nan, best valid loss: -5.21807
2018-04-26 22:00:08.393569: iter 74000 | train loss: nan, valid: nan, best valid loss: -5.21807
2018-04-26 22:00:41.921311: iter 75000 | train loss: nan, valid: nan, best valid loss: -5.21807
2018-04-26 22:01:15.476349: iter 76000 | train loss: nan, valid: nan, best valid loss: -5.21807
2018-04-26 22:01:48.972678: iter 77000 | train loss: nan, valid: nan, best valid loss: -5.21807
2018-04-26 22:02:22.554510: iter 78000 | train loss: nan, valid: nan, best valid loss: -5.21807
2018-04-26 22:02:56.060033: iter 79000 | train loss: nan, valid: nan, best valid loss: -5.21807
2018-04-26 22:03:29.712671: iter 80000 | train loss: nan, valid: nan, best valid loss: -5.21807
2018-04-26 22:04:03.214801: iter 81000 | train loss: nan, valid: nan, best valid loss: -5.21807
2018-04-26 22:04:36.761498: iter 82000 | train loss: nan, valid: nan, best valid loss: -5.21807
2018-04-26 22:05:10.268570: iter 83000 | train loss: nan, valid: nan, best valid loss: -5.21807
2018-04-26 22:05:43.801581: iter 84000 | train loss: nan, valid: nan, best valid loss: -5.21807
2018-04-26 22:06:17.323266: iter 85000 | train loss: nan, valid: nan, best valid loss: -5.21807
2018-04-26 22:06:50.878742: iter 86000 | train loss: nan, valid: nan, best valid loss: -5.21807
2018-04-26 22:07:24.474222: iter 87000 | train loss: nan, valid: nan, best valid loss: -5.21807
2018-04-26 22:07:57.990509: iter 88000 | train loss: nan, valid: nan, best valid loss: -5.21807
2018-04-26 22:08:31.565712: iter 89000 | train loss: nan, valid: nan, best valid loss: -5.21807
2018-04-26 22:09:05.060036: iter 90000 | train loss: nan, valid: nan, best valid loss: -5.21807
2018-04-26 22:09:38.603455: iter 91000 | train loss: nan, valid: nan, best valid loss: -5.21807
2018-04-26 22:10:12.075326: iter 92000 | train loss: nan, valid: nan, best valid loss: -5.21807
2018-04-26 22:10:45.647688: iter 93000 | train loss: nan, valid: nan, best valid loss: -5.21807
2018-04-26 22:11:19.137479: iter 94000 | train loss: nan, valid: nan, best valid loss: -5.21807
2018-04-26 22:11:52.690870: iter 95000 | train loss: nan, valid: nan, best valid loss: -5.21807
2018-04-26 22:12:26.211153: iter 96000 | train loss: nan, valid: nan, best valid loss: -5.21807
2018-04-26 22:12:59.863952: iter 97000 | train loss: nan, valid: nan, best valid loss: -5.21807
2018-04-26 22:13:33.411406: iter 98000 | train loss: nan, valid: nan, best valid loss: -5.21807
2018-04-26 22:14:06.894105: iter 99000 | train loss: nan, valid: nan, best valid loss: -5.21807
2018-04-27 20:33:24.968812: iter 0 | train loss: 0.10597, valid: -0.58307, best valid loss: -0.58307
2018-04-27 20:34:02.916000: iter 1000 | train loss: -0.69154, valid: -0.73072, best valid loss: -0.73072
