2018-04-27 20:45:42.549742: iter 0 | train loss: -3.75768, valid: -6.57352, best valid loss: -6.57352
2018-04-27 20:46:24.848330: iter 1000 | train loss: -7.51094, valid: -7.98510, best valid loss: -7.98510
2018-04-27 20:47:07.111393: iter 2000 | train loss: -7.84648, valid: -8.26925, best valid loss: -8.26925
2018-04-27 20:47:49.391651: iter 3000 | train loss: -8.62571, valid: -9.12889, best valid loss: -9.12889
2018-04-27 20:48:31.665875: iter 4000 | train loss: -8.96529, valid: -9.71186, best valid loss: -9.71186
2018-04-27 20:49:13.719724: iter 5000 | train loss: -9.64232, valid: -9.71651, best valid loss: -9.71651
2018-04-27 20:49:55.784960: iter 6000 | train loss: -10.19965, valid: -10.65367, best valid loss: -10.65367
2018-04-27 20:50:37.992966: iter 7000 | train loss: -10.13852, valid: -10.81250, best valid loss: -10.81250
2018-04-27 20:51:03.030528: iter 0 | train loss: -2.00688, valid: -4.77547, best valid loss: -4.77547
2018-04-27 20:51:20.066737: iter 8000 | train loss: -10.62741, valid: -8.90582, best valid loss: -10.81250
2018-04-27 20:51:40.551512: iter 1000 | train loss: -6.00068, valid: -6.28459, best valid loss: -6.28459
2018-04-27 20:52:02.233890: iter 9000 | train loss: -10.17753, valid: -11.07672, best valid loss: -11.07672
2018-04-27 20:52:18.170416: iter 2000 | train loss: -7.12693, valid: -6.85478, best valid loss: -6.85478
2018-04-27 20:52:44.396279: iter 10000 | train loss: -10.99797, valid: -11.39554, best valid loss: -11.39554
2018-04-27 20:52:55.785570: iter 3000 | train loss: -7.27921, valid: -8.42552, best valid loss: -8.42552
2018-04-27 20:53:26.538616: iter 11000 | train loss: -11.14446, valid: -11.52189, best valid loss: -11.52189
2018-04-27 20:53:33.298748: iter 4000 | train loss: -8.25564, valid: -8.54944, best valid loss: -8.54944
2018-04-27 20:54:08.771527: iter 12000 | train loss: -11.35400, valid: -11.54480, best valid loss: -11.54480
2018-04-27 20:54:11.024947: iter 5000 | train loss: -9.09157, valid: -9.90864, best valid loss: -9.90864
2018-04-27 20:54:48.593627: iter 6000 | train loss: -9.78765, valid: -10.30902, best valid loss: -10.30902
2018-04-27 20:54:50.971749: iter 13000 | train loss: -11.28626, valid: -11.92477, best valid loss: -11.92477
2018-04-27 20:55:26.292872: iter 7000 | train loss: -10.08213, valid: -10.75445, best valid loss: -10.75445
2018-04-27 20:55:32.972032: iter 14000 | train loss: -11.44795, valid: -11.53762, best valid loss: -11.92477
2018-04-27 20:56:03.706215: iter 8000 | train loss: -10.51697, valid: -10.74586, best valid loss: -10.75445
2018-04-27 20:56:14.994222: iter 15000 | train loss: -11.85003, valid: -11.84755, best valid loss: -11.92477
2018-04-27 20:56:41.163069: iter 9000 | train loss: -10.69538, valid: -10.53890, best valid loss: -10.75445
2018-04-27 20:56:56.992222: iter 16000 | train loss: -11.97465, valid: -11.88674, best valid loss: -11.92477
2018-04-27 20:57:18.663108: iter 10000 | train loss: -11.27299, valid: -11.14640, best valid loss: -11.14640
2018-04-27 20:57:39.008823: iter 17000 | train loss: -11.89544, valid: -11.87252, best valid loss: -11.92477
2018-04-27 20:57:56.109906: iter 11000 | train loss: -10.94798, valid: -11.06351, best valid loss: -11.14640
2018-04-27 20:58:21.218020: iter 18000 | train loss: -12.23370, valid: -12.59951, best valid loss: -12.59951
2018-04-27 20:58:33.667356: iter 12000 | train loss: -11.53854, valid: -11.71871, best valid loss: -11.71871
2018-04-27 20:59:03.164325: iter 19000 | train loss: -12.08556, valid: -12.32183, best valid loss: -12.59951
2018-04-27 20:59:11.277601: iter 13000 | train loss: -11.32315, valid: -11.98399, best valid loss: -11.98399
2018-04-27 20:59:45.198197: iter 20000 | train loss: -12.34906, valid: -12.38082, best valid loss: -12.59951
2018-04-27 20:59:48.672226: iter 14000 | train loss: -11.47600, valid: -11.32974, best valid loss: -11.98399
2018-04-27 21:00:26.407628: iter 15000 | train loss: -11.72802, valid: -12.10417, best valid loss: -12.10417
2018-04-27 21:00:27.235070: iter 21000 | train loss: -12.58341, valid: -12.45038, best valid loss: -12.59951
2018-04-27 21:01:03.870491: iter 16000 | train loss: -11.63054, valid: -11.32445, best valid loss: -12.10417
2018-04-27 21:01:09.548700: iter 22000 | train loss: -12.75177, valid: -12.73111, best valid loss: -12.73111
2018-04-27 21:01:41.417253: iter 17000 | train loss: -11.69390, valid: -11.97322, best valid loss: -12.10417
2018-04-27 21:01:51.662548: iter 23000 | train loss: -12.57838, valid: -12.66866, best valid loss: -12.73111
2018-04-27 21:02:19.029849: iter 18000 | train loss: -12.22141, valid: -12.56352, best valid loss: -12.56352
2018-04-27 21:02:33.619807: iter 24000 | train loss: -12.66635, valid: -12.67323, best valid loss: -12.73111
2018-04-27 21:02:56.422075: iter 19000 | train loss: -12.05524, valid: -12.30982, best valid loss: -12.56352
2018-04-27 21:03:15.540234: iter 25000 | train loss: -12.88302, valid: -12.68211, best valid loss: -12.73111
2018-04-27 21:03:33.867533: iter 20000 | train loss: -12.32800, valid: -12.44837, best valid loss: -12.56352
2018-04-27 21:03:57.563176: iter 26000 | train loss: -12.98856, valid: -13.12743, best valid loss: -13.12743
2018-04-27 21:04:11.536853: iter 21000 | train loss: -12.46492, valid: -12.90162, best valid loss: -12.90162
2018-04-27 21:04:39.541307: iter 27000 | train loss: -12.95751, valid: -13.30916, best valid loss: -13.30916
2018-04-27 21:04:49.005190: iter 22000 | train loss: -12.59438, valid: -12.20370, best valid loss: -12.90162
2018-04-27 21:05:22.614235: iter 28000 | train loss: -13.02218, valid: -13.14156, best valid loss: -13.30916
2018-04-27 21:05:26.370563: iter 23000 | train loss: -12.63740, valid: -12.62072, best valid loss: -12.90162
2018-04-27 21:06:03.852046: iter 24000 | train loss: -12.63255, valid: -12.42839, best valid loss: -12.90162
2018-04-27 21:06:06.046960: iter 29000 | train loss: -13.01450, valid: -13.29165, best valid loss: -13.30916
2018-04-27 21:06:41.370819: iter 25000 | train loss: -12.62946, valid: -12.86584, best valid loss: -12.90162
2018-04-27 21:06:47.691920: iter 30000 | train loss: -13.01731, valid: -13.51132, best valid loss: -13.51132
2018-04-27 21:07:18.848315: iter 26000 | train loss: -12.82100, valid: -12.76008, best valid loss: -12.90162
2018-04-27 21:07:31.216609: iter 31000 | train loss: -13.26252, valid: -13.34015, best valid loss: -13.51132
2018-04-27 21:07:56.502105: iter 27000 | train loss: -12.90498, valid: -13.18766, best valid loss: -13.18766
2018-04-27 21:08:12.764726: iter 32000 | train loss: -13.21606, valid: -13.25146, best valid loss: -13.51132
2018-04-27 21:08:33.932144: iter 28000 | train loss: -12.97743, valid: -13.04133, best valid loss: -13.18766
2018-04-27 21:08:54.251861: iter 33000 | train loss: -13.35444, valid: -13.42785, best valid loss: -13.51132
2018-04-27 21:09:11.335850: iter 29000 | train loss: -13.03076, valid: -12.90216, best valid loss: -13.18766
2018-04-27 21:09:36.334740: iter 34000 | train loss: -13.43090, valid: -13.08484, best valid loss: -13.51132
2018-04-27 21:09:48.761363: iter 30000 | train loss: -12.82022, valid: -13.01094, best valid loss: -13.18766
2018-04-27 21:10:17.879569: iter 35000 | train loss: -13.27986, valid: -13.59677, best valid loss: -13.59677
2018-04-27 21:10:26.150011: iter 31000 | train loss: -13.06089, valid: -12.92813, best valid loss: -13.18766
2018-04-27 21:10:59.343488: iter 36000 | train loss: -13.45992, valid: -13.60118, best valid loss: -13.60118
2018-04-27 21:11:03.647179: iter 32000 | train loss: -13.30716, valid: -13.13246, best valid loss: -13.18766
2018-04-27 21:11:40.702532: iter 37000 | train loss: -13.51555, valid: -13.69349, best valid loss: -13.69349
2018-04-27 21:11:41.386269: iter 33000 | train loss: -13.44533, valid: -13.65296, best valid loss: -13.65296
2018-04-27 21:12:18.916427: iter 34000 | train loss: -13.52551, valid: -13.91599, best valid loss: -13.91599
2018-04-27 21:12:21.902409: iter 38000 | train loss: -13.66939, valid: -13.16100, best valid loss: -13.69349
2018-04-27 21:12:56.444273: iter 35000 | train loss: -13.60132, valid: -13.21143, best valid loss: -13.91599
2018-04-27 21:13:03.125375: iter 39000 | train loss: -13.32974, valid: -13.42614, best valid loss: -13.69349
2018-04-27 21:13:33.908043: iter 36000 | train loss: -13.68847, valid: -13.78106, best valid loss: -13.91599
2018-04-27 21:13:44.405768: iter 40000 | train loss: -13.66165, valid: -13.72592, best valid loss: -13.72592
2018-04-27 21:14:11.420289: iter 37000 | train loss: -13.41759, valid: -13.69792, best valid loss: -13.91599
2018-04-27 21:14:25.513543: iter 41000 | train loss: -13.50461, valid: -13.15637, best valid loss: -13.72592
2018-04-27 21:14:48.802335: iter 38000 | train loss: -13.70121, valid: -13.11324, best valid loss: -13.91599
2018-04-27 21:15:06.695569: iter 42000 | train loss: -13.62184, valid: -13.98876, best valid loss: -13.98876
2018-04-27 21:15:26.270168: iter 39000 | train loss: -13.57021, valid: -13.19706, best valid loss: -13.91599
2018-04-27 21:15:47.681717: iter 43000 | train loss: -13.57966, valid: -13.72222, best valid loss: -13.98876
2018-04-27 21:16:03.625124: iter 40000 | train loss: -13.47218, valid: -13.60038, best valid loss: -13.91599
2018-04-27 21:16:28.806355: iter 44000 | train loss: -13.78395, valid: -14.04809, best valid loss: -14.04809
2018-04-27 21:16:41.084969: iter 41000 | train loss: -13.65204, valid: -12.85372, best valid loss: -13.91599
2018-04-27 21:17:10.160547: iter 45000 | train loss: -13.85522, valid: -14.18012, best valid loss: -14.18012
2018-04-27 21:17:18.513349: iter 42000 | train loss: -13.72097, valid: -13.18705, best valid loss: -13.91599
2018-04-27 21:17:51.191246: iter 46000 | train loss: -13.94967, valid: -14.17004, best valid loss: -14.18012
2018-04-27 21:17:55.952102: iter 43000 | train loss: -13.69220, valid: -13.74692, best valid loss: -13.91599
2018-04-27 21:18:32.298516: iter 47000 | train loss: -14.01319, valid: -14.31081, best valid loss: -14.31081
2018-04-27 21:18:33.368803: iter 44000 | train loss: -13.79154, valid: -13.58979, best valid loss: -13.91599
2018-04-27 21:19:11.021830: iter 45000 | train loss: -13.81148, valid: -13.85007, best valid loss: -13.91599
2018-04-27 21:19:13.716991: iter 48000 | train loss: -13.89031, valid: -14.66393, best valid loss: -14.66393
2018-04-27 21:19:48.605783: iter 46000 | train loss: -13.85989, valid: -14.25890, best valid loss: -14.25890
2018-04-27 21:19:54.653390: iter 49000 | train loss: -14.02842, valid: -13.71734, best valid loss: -14.66393
2018-04-27 21:20:26.025086: iter 47000 | train loss: -13.83415, valid: -14.12248, best valid loss: -14.25890
2018-04-27 21:20:35.739281: iter 50000 | train loss: -13.99697, valid: -13.87049, best valid loss: -14.66393
2018-04-27 21:21:03.486769: iter 48000 | train loss: -13.81272, valid: -13.91348, best valid loss: -14.25890
2018-04-27 21:21:17.152958: iter 51000 | train loss: -14.10152, valid: -14.68099, best valid loss: -14.68099
2018-04-27 21:21:41.077121: iter 49000 | train loss: -13.89673, valid: -14.49550, best valid loss: -14.49550
2018-04-27 21:21:58.079532: iter 52000 | train loss: -14.04248, valid: -13.99775, best valid loss: -14.68099
2018-04-27 21:22:18.616733: iter 50000 | train loss: -13.88927, valid: -14.19519, best valid loss: -14.49550
2018-04-27 21:22:39.206909: iter 53000 | train loss: -14.11538, valid: -14.09715, best valid loss: -14.68099
2018-04-27 21:22:56.020789: iter 51000 | train loss: -13.92777, valid: -14.19943, best valid loss: -14.49550
2018-04-27 21:23:20.250430: iter 54000 | train loss: -14.21589, valid: -14.67567, best valid loss: -14.68099
2018-04-27 21:23:33.526407: iter 52000 | train loss: -14.05987, valid: -14.02282, best valid loss: -14.49550
2018-04-27 21:24:01.292697: iter 55000 | train loss: -14.19066, valid: -14.56497, best valid loss: -14.68099
2018-04-27 21:24:10.966848: iter 53000 | train loss: -14.06348, valid: -14.09489, best valid loss: -14.49550
2018-04-27 21:24:42.457759: iter 56000 | train loss: -14.37022, valid: -14.38925, best valid loss: -14.68099
2018-04-27 21:24:48.448456: iter 54000 | train loss: -14.07442, valid: -14.47194, best valid loss: -14.49550
2018-04-27 21:25:23.429461: iter 57000 | train loss: -14.21017, valid: -14.26905, best valid loss: -14.68099
2018-04-27 21:25:25.898765: iter 55000 | train loss: -13.94610, valid: -14.12872, best valid loss: -14.49550
2018-04-27 21:26:03.427246: iter 56000 | train loss: -14.22230, valid: -14.27160, best valid loss: -14.49550
2018-04-27 21:26:04.447196: iter 58000 | train loss: -14.47652, valid: -14.55531, best valid loss: -14.68099
2018-04-27 21:26:40.851663: iter 57000 | train loss: -14.22029, valid: -14.49234, best valid loss: -14.49550
2018-04-27 21:26:45.509622: iter 59000 | train loss: -14.36489, valid: -13.94445, best valid loss: -14.68099
2018-04-27 21:27:18.373125: iter 58000 | train loss: -14.28342, valid: -14.14970, best valid loss: -14.49550
2018-04-27 21:27:26.467773: iter 60000 | train loss: -14.28441, valid: -14.18341, best valid loss: -14.68099
2018-04-27 21:27:55.821752: iter 59000 | train loss: -14.33156, valid: -14.06967, best valid loss: -14.49550
2018-04-27 21:28:07.419634: iter 61000 | train loss: -14.45070, valid: -14.52021, best valid loss: -14.68099
2018-04-27 21:28:33.349412: iter 60000 | train loss: -14.20163, valid: -13.99010, best valid loss: -14.49550
2018-04-27 21:28:48.542540: iter 62000 | train loss: -14.52495, valid: -14.63754, best valid loss: -14.68099
2018-04-27 21:29:10.774257: iter 61000 | train loss: -14.46513, valid: -14.37638, best valid loss: -14.49550
2018-04-27 21:29:29.541678: iter 63000 | train loss: -14.56862, valid: -14.38365, best valid loss: -14.68099
2018-04-27 21:29:48.193720: iter 62000 | train loss: -14.42514, valid: -14.43641, best valid loss: -14.49550
2018-04-27 21:30:10.641019: iter 64000 | train loss: -14.55606, valid: -14.77297, best valid loss: -14.77297
2018-04-27 21:30:25.798565: iter 63000 | train loss: -14.47355, valid: -14.89161, best valid loss: -14.89161
2018-04-27 21:30:51.690595: iter 65000 | train loss: -14.54654, valid: -14.41932, best valid loss: -14.77297
2018-04-27 21:31:03.276886: iter 64000 | train loss: -14.60759, valid: -14.51611, best valid loss: -14.89161
2018-04-27 21:31:32.684570: iter 66000 | train loss: -14.62238, valid: -14.64373, best valid loss: -14.77297
2018-04-27 21:31:40.791366: iter 65000 | train loss: -14.52141, valid: -14.89572, best valid loss: -14.89572
2018-04-27 21:32:13.662615: iter 67000 | train loss: -14.71011, valid: -14.72953, best valid loss: -14.77297
2018-04-27 21:32:18.262589: iter 66000 | train loss: -14.74730, valid: -14.86074, best valid loss: -14.89572
2018-04-27 21:32:54.679596: iter 68000 | train loss: -14.44783, valid: -14.43035, best valid loss: -14.77297
2018-04-27 21:32:55.741330: iter 67000 | train loss: -14.76035, valid: -14.76707, best valid loss: -14.89572
2018-04-27 21:33:33.388017: iter 68000 | train loss: -14.80479, valid: -14.94603, best valid loss: -14.94603
2018-04-27 21:33:35.746533: iter 69000 | train loss: -14.53241, valid: -14.87176, best valid loss: -14.87176
2018-04-27 21:34:11.000977: iter 69000 | train loss: -14.74889, valid: -15.11992, best valid loss: -15.11992
2018-04-27 21:34:16.742533: iter 70000 | train loss: -14.62875, valid: -14.74259, best valid loss: -14.87176
2018-04-27 21:34:48.422680: iter 70000 | train loss: -14.80202, valid: -15.02291, best valid loss: -15.11992
2018-04-27 21:34:57.691240: iter 71000 | train loss: -14.73098, valid: -14.28805, best valid loss: -14.87176
2018-04-27 21:35:25.925528: iter 71000 | train loss: -14.87339, valid: -14.94908, best valid loss: -15.11992
2018-04-27 21:35:38.763114: iter 72000 | train loss: -14.55879, valid: -15.14863, best valid loss: -15.14863
2018-04-27 21:36:03.358561: iter 72000 | train loss: -14.83026, valid: -14.91044, best valid loss: -15.11992
2018-04-27 21:36:19.828982: iter 73000 | train loss: -14.86647, valid: -15.28407, best valid loss: -15.28407
2018-04-27 21:36:40.946570: iter 73000 | train loss: -14.97578, valid: -15.11358, best valid loss: -15.11992
2018-04-27 21:37:00.736624: iter 74000 | train loss: -14.73232, valid: -14.47373, best valid loss: -15.28407
2018-04-27 21:37:18.347777: iter 74000 | train loss: -14.82706, valid: -14.51551, best valid loss: -15.11992
2018-04-27 21:37:41.744523: iter 75000 | train loss: -14.73011, valid: -14.37434, best valid loss: -15.28407
2018-04-27 21:37:55.783213: iter 75000 | train loss: -14.85155, valid: -14.64379, best valid loss: -15.11992
2018-04-27 21:38:22.638036: iter 76000 | train loss: -14.84330, valid: -14.47621, best valid loss: -15.28407
2018-04-27 21:38:33.148001: iter 76000 | train loss: -15.02567, valid: -14.72568, best valid loss: -15.11992
2018-04-27 21:39:03.556927: iter 77000 | train loss: -14.74694, valid: -15.07752, best valid loss: -15.28407
2018-04-27 21:39:10.566678: iter 77000 | train loss: -14.94372, valid: -14.76748, best valid loss: -15.11992
2018-04-27 21:39:44.468403: iter 78000 | train loss: -14.89683, valid: -15.18718, best valid loss: -15.28407
2018-04-27 21:39:48.321987: iter 78000 | train loss: -15.11098, valid: -15.32550, best valid loss: -15.32550
2018-04-27 21:40:25.385369: iter 79000 | train loss: -14.89922, valid: -14.68763, best valid loss: -15.28407
2018-04-27 21:40:25.764063: iter 79000 | train loss: -15.03286, valid: -14.83705, best valid loss: -15.32550
2018-04-27 21:41:03.142324: iter 80000 | train loss: -15.00942, valid: -15.03360, best valid loss: -15.32550
2018-04-27 21:41:06.329827: iter 80000 | train loss: -14.81576, valid: -15.00353, best valid loss: -15.28407
2018-04-27 21:41:40.548742: iter 81000 | train loss: -15.13042, valid: -15.14135, best valid loss: -15.32550
2018-04-27 21:41:47.171083: iter 81000 | train loss: -15.04853, valid: -15.04087, best valid loss: -15.28407
2018-04-27 21:42:18.526542: iter 82000 | train loss: -15.07868, valid: -15.46209, best valid loss: -15.46209
2018-04-27 21:42:28.092552: iter 82000 | train loss: -14.92186, valid: -14.68027, best valid loss: -15.28407
2018-04-27 21:42:55.920282: iter 83000 | train loss: -15.08404, valid: -14.96495, best valid loss: -15.46209
2018-04-27 21:43:08.941359: iter 83000 | train loss: -14.92277, valid: -14.84024, best valid loss: -15.28407
2018-04-27 21:43:33.371364: iter 84000 | train loss: -15.05749, valid: -14.88660, best valid loss: -15.46209
2018-04-27 21:43:49.864482: iter 84000 | train loss: -14.91908, valid: -14.84823, best valid loss: -15.28407
2018-04-27 21:44:10.827727: iter 85000 | train loss: -15.14023, valid: -15.27869, best valid loss: -15.46209
2018-04-27 21:44:30.791901: iter 85000 | train loss: -14.97127, valid: -14.81299, best valid loss: -15.28407
2018-04-27 21:44:48.340974: iter 86000 | train loss: -15.13661, valid: -15.31765, best valid loss: -15.46209
2018-04-27 21:45:11.662057: iter 86000 | train loss: -15.04562, valid: -14.99356, best valid loss: -15.28407
2018-04-27 21:45:25.919529: iter 87000 | train loss: -15.27810, valid: -15.51279, best valid loss: -15.51279
2018-04-27 21:45:52.737814: iter 87000 | train loss: -15.10901, valid: -15.40137, best valid loss: -15.40137
2018-04-27 21:46:03.587851: iter 88000 | train loss: -15.27288, valid: -15.55934, best valid loss: -15.55934
2018-04-27 21:46:33.694867: iter 88000 | train loss: -15.10244, valid: -15.45544, best valid loss: -15.45544
2018-04-27 21:46:40.935930: iter 89000 | train loss: -15.33016, valid: -15.54954, best valid loss: -15.55934
2018-04-27 21:47:14.580261: iter 89000 | train loss: -15.11109, valid: -14.67463, best valid loss: -15.45544
2018-04-27 21:47:18.368213: iter 90000 | train loss: -15.37550, valid: -15.12379, best valid loss: -15.55934
2018-04-27 21:47:55.499328: iter 90000 | train loss: -15.22831, valid: -15.34304, best valid loss: -15.45544
2018-04-27 21:47:55.866995: iter 91000 | train loss: -15.39672, valid: -15.17786, best valid loss: -15.55934
2018-04-27 21:48:33.404002: iter 92000 | train loss: -15.35216, valid: -15.30366, best valid loss: -15.55934
2018-04-27 21:48:36.408673: iter 91000 | train loss: -15.24689, valid: -15.05600, best valid loss: -15.45544
2018-04-27 21:49:10.826626: iter 93000 | train loss: -15.34002, valid: -15.43554, best valid loss: -15.55934
2018-04-27 21:49:17.364739: iter 92000 | train loss: -15.19495, valid: -14.97803, best valid loss: -15.45544
2018-04-27 21:49:48.603471: iter 94000 | train loss: -15.49289, valid: -15.64562, best valid loss: -15.64562
2018-04-27 21:49:58.252957: iter 93000 | train loss: -15.22378, valid: -15.30533, best valid loss: -15.45544
2018-04-27 21:50:26.003862: iter 95000 | train loss: -15.42322, valid: -15.22866, best valid loss: -15.64562
2018-04-27 21:50:39.157353: iter 94000 | train loss: -15.36483, valid: -15.41433, best valid loss: -15.45544
2018-04-27 21:51:03.474809: iter 96000 | train loss: -15.44586, valid: -15.60420, best valid loss: -15.64562
2018-04-27 21:51:20.038954: iter 95000 | train loss: -15.12661, valid: -14.95971, best valid loss: -15.45544
2018-04-27 21:51:40.929291: iter 97000 | train loss: -15.07969, valid: -15.39088, best valid loss: -15.64562
2018-04-27 21:52:01.106772: iter 96000 | train loss: -15.28902, valid: -15.60819, best valid loss: -15.60819
2018-04-27 21:52:18.430830: iter 98000 | train loss: -15.51661, valid: -15.38400, best valid loss: -15.64562
2018-04-27 21:52:42.020405: iter 97000 | train loss: -15.40556, valid: -15.39392, best valid loss: -15.60819
2018-04-27 21:52:56.139756: iter 99000 | train loss: -15.61013, valid: -15.72990, best valid loss: -15.72990
2018-04-27 21:53:22.988438: iter 98000 | train loss: -15.38523, valid: -15.62924, best valid loss: -15.62924
2018-04-27 21:54:03.975048: iter 99000 | train loss: -15.42297, valid: -14.72029, best valid loss: -15.62924
